% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SmultiRaSE.R
\name{SmultiRase}
\alias{SmultiRase}
\title{Construct the super multi-label random subspace ensemble classifier.}
\usage{
SmultiRase(
  xtrain,
  ytrain,
  xval = NULL,
  yval = NULL,
  B1 = 50,
  B2 = 100,
  D = NULL,
  dist = NULL,
  base = "lda",
  super = list(type = "seperate", base.update = TRUE),
  criterion = "cv",
  ranking = TRUE,
  k = c(3, 5, 7, 9, 11),
  cores = 1,
  seed = NULL,
  iteration = 1,
  cutoff = TRUE,
  cv = 5,
  scale = FALSE,
  C0 = 0.1,
  kl.k = NULL,
  lower.limits = NULL,
  upper.limits = NULL,
  weights = NULL,
  ...
)
}
\arguments{
\item{xtrain}{n * p observation matrix. n observations, p features.}

\item{ytrain}{n observations with k classes.}

\item{B1}{the number of weak learners. Default = 200.}

\item{B2}{the number of subspace candidates generated for each weak learner. Default = 500.}

\item{D_max}{the maximal subspace size when generating random subspaces. Default = NULL, which is \eqn{floor(min(\sqrt n, p))}. For classical RaSE with a single classifier type, D_max is a positive integer. For super RaSE with multiple classifier types, D_max is a vector indicating different maximum D values used for each base classifier type (the corresponding classifier types should be noted in the names of the vector).}
}
\description{
\code{SmRaSE} is a general ensemble classification framework, adapted from RaSE algorithm, to solve the sparse multi class classification problem. Like RaSE algorithm, for each of the B1 weak learners, B2 random subspaces are generated and the optimal one is chosen to train the model on the basis of some criterion.
}
\examples{
set.seed(0, kind = "L'Ecuyer-CMRG")
train.data <- RaModel("multi_classification", model.no = 1, n = 100,
p = 50, p0 = rep(1/4,4))
test.data <- RaModel("multi_classification", model.no = 1, n = 100,
p = 50, p0 = rep(1/4,4))
xtrain <- train.data$x
colnames(xtrain) <- paste0("V",1:dim(xtrain)[2])
ytrain <- train.data$y
xtest <- test.data$x
colnames(xtest) <- paste0("V",1:dim(xtest)[2])
ytest <- test.data$y

# test mRaSE classifier with LDA base classifier
fit <- SmultiRase(xtrain, ytrain, B1 = 20, B2 = 50, iteration = 0,
base = 'lda', cores = 1)
mean(predict(fit, xtest) != ytest)

\dontrun{
# test mRaSE classifier with LDA base classifier and 1 iteration round
fit <- SmultiRase(xtrain, ytrain, B1 = 20, B2 = 50, iteration = 1,
base = 'lda', cores = 6)
mean(predict(fit, xtest) != ytest)

# test mRaSE classifier with KNN base classifier
fit <- SmultiRase(xtrain, ytrain, B1 = 20, B2 = 50, iteration = 0,
base = 'knn', cores = 6)
mean(predict(fit, xtest) != ytest)

# test mRaSE classifier with logistic regression base classifier
fit <- SmultiRase(xtrain, ytrain, B1 = 20, B2 = 50, iteration = 0,
base = 'logistic', cores = 6)
mean(predict(fit, xtest) != ytest)

# test mRaSE classifier with tree base classifier
fit <- SmultiRase(xtrain, ytrain, B1 = 20, B2 = 50, iteration = 0,
base = 'svm', cores = 6)
mean(predict(fit, xtest) != ytest)

# test mRaSE classifier with tree base classifier
fit <- SmultiRase(xtrain, ytrain, B1 = 20, B2 = 50, iteration = 0,
base = 'tree', cores = 6)
mean(predict(fit, xtest) != ytest)

# fit a super RaSE classifier by sampling base learner from kNN, LDA and logistic
# regression in equal probability
fit <- SmultiRase(xtrain, ytrain, B1 = 20, B2 = 50,
base = c("knn", "lda", "logistic"), iteration = 1, cores = 6)
mean(predict(fit, xtest) != ytest)

}
}
\seealso{
\code{\link{predict.SmultiRaSE}}.
}
